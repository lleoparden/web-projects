<!DOCTYPE html>
<html>
<head>
</head>
<body>
    <br>
    <h5>Company</h5>
    <h1><b>X's report in compliance with <br> Regulation (EU) 2021/1232</b></h1>
    <div>
        <h5>Sunday, 19 May 2024</h5>
        <a href="https://www.facebook.com">
             <img src="https://upload.wikimedia.org/wikipedia/commons/b/b9/2023_Facebook_icon.svg" title = "share with facebook" width="20px"></a>
        
        <a href="https://x.com/?lang=en">
            <img src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcS7fj1vqat9XLO4cFwOG1uFqLXYDcISiYil2w&s" title = "share with x" width="20px"></a>
        
        <a href="https://www.linkedin.com/?trk=Officekey">
            <img src="https://t4.ftcdn.net/jpg/06/04/68/99/360_F_604689984_50VpKqlFBCOvSC54HM8Z92uneHoIJ1F9.jpg" title = "share with linkedin" width="20px"></a>
        
        <a href="https://blog.x.com/en_us/topics/company/2022/twitter-s-eu-submission-for-2021-1232">
            <img src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSNUbMSTFqkZjUF6Ir6_HaSqqCba2wfNLUqiQ&s" title = "copy link" width="20px"></a>
       
    </div>
    <p><b><i>Submitted and uploaded on 19 May 2024</i></b></p>
    <p>
        <b>
            X REPORT (PERIOD OF JANUARY 1 2023 - DECEMBER 31 2023)
        </b>
    </p>
    <p>
        Under Article 3(1)(g)(vii) of Regulation (EU) 2021/1232 concerning a temporary derogation <br>
        from certain provisions of Directive 2002/58/EC regarding the use of technologies by <br>
        providers of number-independent interpersonal communication services for processing <br>
        personal and other data to combat online child sexual abuse (‚ÄúEU CSAM Derogation‚Äù), which<br>
        entered into force on 2 August 2021, Twitter International Unlimited Company (‚ÄúTIUC‚Äù) is <br>
        required to compile, publish, and submit this report to both the Irish Data Protection<br>
        Commission (‚ÄúIDPC‚Äù) and the European Commission (‚ÄúEC‚Äù). This report specifically covers <br>
        the period from 1 January 2023 to 31 December 2023, inclusive.
    </p>
    <p>
        Please note that the content of this report is specifically tailored to address measures within <br>
        the purview of the EU CSAM Derogation. As such, it focuses on the actions and initiatives<br>
        directly related to the regulation and its requirements for combating online Child Sexual<br>
        Exploitation (‚ÄúCSE‚Äù). This report does not encompass the entirety of efforts and measures<br>
        employed by our platform to protect children.
    </p>

    <h2>Overview</h2>
        
    <p>           
        ùïè is committed to facilitating the public conversation in a responsible manner. Integral to this<br>
        commitment is  ùïè's 
        <a href="https://help.x.com/en/rules-and-policies/child-safety">zero tolerance policy towards CSE on our platform</a>. We strictly prohibit any<br>
        content that features, promotes or glorifies CSE, including but not limited to, media, text, <br>
        content, or computer-generated images.
    </p>
    
    <p>
        Our policy underscores that the act of viewing, sharing, or linking to CSE material not only<br>
        contributes to the re-victimisation of the depicted minors but also violates our platform‚Äôs<br>
        guidelines. This stance extends to any content that could further contribute to the<br>
        victimisation of children by promoting or glorifying CSE.
    </p>

    <h2>Our Approach</h2>

    <p>
        We are deeply committed to protecting children globally from CSE. Our approach<br>
        encompasses the development of advanced technological solutions, comprehensive training<br>
        of our content moderators, continued support for law enforcement, and ongoing partnerships<br>
        to address and prevent CSE effectively.
    </p>
    <p>
        Our approach integrates machine learning algorithms with human oversight to efficiently<br>
        identify and assess content that potentially violates our policies against CSE. Our systems<br>
        flag content for review, enabling our human moderators to consider crucial contextual<br>
        information in their decision-making process. This work is led by an international, cross-<br>
        functional team that provides 24-hour monitoring in multiple languages, ensuring rapid and<br>
        effective responses to emerging threats.
    </p>
    <p>
        Upon identification of CSE media, including images, videos, or any content that promotes<br>
        child exploitation, we remove such material from our platform without further notice and<br>
        report it to The National Center for Missing & Exploited Children (‚ÄúNCMEC‚Äù). NCMEC plays a<br>
        pivotal role in coordinating with law enforcement agencies worldwide to support<br>
        investigations and legal actions. Benefiting from robust partnerships with law enforcement<br>
        bodies, NGOs, and the INHOPE network, NCMEC is instrumental in our collective efforts to<br>
        eradicate CSE.
    </p>
    <p>
        In December 2022, we embarked on a significant partnership with Thorn, utilising its Safer<br>
        product to substantially increase our capacity to identify, remove, and report violative<br>
        content. Further solidifying our stance against CSE, we are further partnering with the Tech<br>
        Coalition and WeProtect. These partnerships facilitate critical information sharing on<br>
        emerging threats and behavioural patterns associated with CSE, enabling us to stay ahead of<br>
        potential risks and adapt our strategies accordingly.
    </p>
    <p>
        Our dedication to safeguarding children extends to continuous investment in both technology<br>
        and talent. We are committed to enhancing our detection and response mechanisms, actively<br>
        seeking out advanced technologies from third-party developers that can enhance our<br>
        protective measures.
    </p>
    <p>
        We also have instituted an appeal process. This mechanism ensures that decisions to remove<br>
        content or suspend accounts can be reviewed, safeguarding against inaccuracies and<br>
        maintaining our commitment to fairness and transparency.
    </p>
    <p>
        For further information on our approach please visit <a href="https://help.twitter.com/en/rules-and-policies/child-sexual-exploitation-policy">this page</a>
    </p>

    <p>
        ---
    </p>

    <h3>(1) the type and volumes of data processed; </h3>

    <p>
        During the reporting period of 1 January 2023, to 31 December 2023, TIUC took significant<br>
        action in its fight against CSE. We suspended 12.4 million accounts for violations related to<br>
        our CSE policies globally, a substantial increase from 2.3 million accounts in 2022. In the EU,<br>
        we suspended more than 700K accounts during the reporting period. Furthermore, we<br>
        submitted 870,000 reports to NCMEC globally, making a significant uptick in our reporting<br>
        efforts, including our first fully-automated report. This volume is over eight times the number<br>
        reported in 2022. It is important to note that TIUC does not currently track accounts reviewed<br>
        but not actioned for policy violations. However, we may process personal data, including<br>
        account details, text, and media, to investigate potential CSE policy violations.
    </p>


    <h3>(2) the specific ground relied on for the processing pursuant to Regulation (EU)<br>  2016/679;  </h3>

    <p>
        The specific grounds for processing personal data by TIUC are detailed in 
        <a href="https://x.com/en/privacy">
            ùïè's Privacy <br> Policy 
        </a>
        and 
        <a href="https://help.x.com/en/rules-and-policies/child-safety">
        Additional information about data processing
        </a>
        , aligning with Regulation (EU) 2016/679 <br> (‚ÄúGDPR‚Äù).     
    </p>


    <h3>(3) the ground relied on for transfers of personal data outside the Union pursuant to <br> Chapter V of Regulation (EU) 2016/679, where applicable;  </h3>

    <p>
        Consistent with Chapter V of the GDPR, ùïè relies on the European Commission‚Äôs<br>
        adequacy decision or Standard Contractual Clauses (‚ÄúSCCs‚Äù) for the transfers of <br>
        personal data outside the European Union, as detailed in 
        <a href="https://x.com/en/privacy">
            ùïè's Privacy Policy 
        </a>   
    </p>


    <h3>(4) the number of cases of online child sexual abuse identified, differentiating between <br> online child sexual abuse material and solicitation of children; </h3>

    <p>
        While all reported violations contravene  
        <a href="https://help.x.com/en/rules-and-policies/child-safety">
            ùïè‚Äôs CSE policy
        </a>, we currently lack the capability to<br>
        categorically distinguish between online sexual abuse material and the specific context of each piece of<br>
        material, such as the solicitation of children. Nonetheless, the 12.4 million<br>
        account suspensions during this period reflect our commitment to combating all forms of<br>
        CSE.
    </p>


    <h3>(5) The number of cases in which a user has lodged a complaint with the internal<br>  redress mechanism or with a judicial authority and the outcome of such  complaints </h3>

    <p>
        In 2023 we received 224k appeals in the EU for CSE-related actions. 
    </p>


    <h3>(6) The numbers and ratios of errors (false positives) of the different technologies  used </h3>

    <p>
        In 2023 we reversed 1,721 CSE suspensions in the EEA. Of these reversals, 210 of the <br>
        original suspensions were made by automation and 1,511 were applied manually. In 2023 we<br>
        made 500k automated and 200k manual CSE suspensions in the EEA, which translates to a<br>
        precision of over 99% for each method.
    </p>


    <h3>(7) The measures applied to limit the error rate and the error rate achieved </h3>

    <p>
        We continually provide training to our agents to ensure consistent enforcement of our<br>
        policies, thereby guaranteeing a high level of accuracy. For automated defences we sample<br>
        potential actions and label to determine error rate before launch. We deploy a variety of<br>
        stopgaps to ensure we don‚Äôt over-enforce or enforce on high trust accounts. Based on our<br>
        suspensions and appeals volume, we achieved an error rate of less than 0.1%.
    </p>

    <h3>(8) the retention policy and the data protection safeguards applied pursuant to<br> Regulation (EU) 2016/679;  </h3>

    <p>
        TIUC‚Äôs data retention policies are outlined in our 
        <a href="https://x.com/en/privacy">
            ùïè's Privacy Policy 
        </a> 
         We adhere to ISO<br>
         standards for security and privacy, undergoing regular third-party audits as needed to<br>
         ensure the robust protection of the processed data.   
    </p>

    <h3>(9) the names of the organisations acting in the public interest against child sexual<br> abuse with which data has been shared pursuant to this Regulation </h3>

    <p>
        The National Center for Missing and Exploited Children (‚ÄúNCMEC‚Äù) in the United States of<br>
        America (
        <a href="https://www.missingkids.org/">
            https://www.missingkids.org/
        </a>
        ).
    </p>

</body>
</html>